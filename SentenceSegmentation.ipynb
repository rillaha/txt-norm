{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Segmentation\n",
    "## this script records the experiments of en & zh sentence segmentation\n",
    "\n",
    "The idea behind all the nlp tasks is all always all time about applying machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import codecs\n",
    "import pickle\n",
    "import time\n",
    "import nltk.metrics \n",
    "from collections import defaultdict\n",
    "from nltk.classify.util import apply_features, accuracy as eval_accuracy\n",
    "from nltk.metrics import (BigramAssocMeasures, precision as eval_precision,recall as eval_recall, f_measure as eval_f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data time:  1.31391692162\n"
     ]
    }
   ],
   "source": [
    "#training without tokenization\n",
    "t0 = time.time()\n",
    "en = \"/home/work/ssCat/trains.en\"\n",
    "with open(en) as inputen:\n",
    "    tokens = []\n",
    "    boundaries = set()\n",
    "    boundaries_token = set()\n",
    "    offset = 0\n",
    "    for sent in inputen:\n",
    "        sent = sent.strip().split(\" \")\n",
    "        #print sent\n",
    "        if len(sent) >=1:\n",
    "            boundaries_token.add(sent[-1])\n",
    "            tokens.extend(sent)\n",
    "            offset += len(sent)\n",
    "            boundaries.add(offset-1)\n",
    "#print tokens[:2000]    \n",
    "def punct_features(tokens, i):\n",
    "    #print tokens[i]\n",
    "    return {'punct': tokens[i],\\\n",
    "            'punctLastLetter':tokens[i][-1],\\\n",
    "            'punctL2L':tokens[i][-2:],\\\n",
    "            'prepunct':tokens[i-1],\\\n",
    "            'nextpunct':tokens[i+1],\\\n",
    "            'prepunctdigit':tokens[i-1].isdigit(),\\\n",
    "           'punctCapi': tokens[i][0].isupper(),\\\n",
    "           'next1letterCapi': tokens[i+1][0].isupper(),\\\n",
    "           'pre1LetterCap': tokens[i-1][0].isupper(),\\\n",
    "           'pre2LetterCap': tokens[i-2][0].isupper()}\n",
    "\n",
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\\\n",
    "               for i in range(2, len(tokens)-2) if tokens[i] in boundaries_token]\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "size_dev = int(len(train_set)*0.2)\n",
    "train_set,dev_set = train_set[size_dev:], train_set[:size_dev]\n",
    "print \"processing data time: \",time.time()-t0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634978\n",
      "processing data time:  12.5063760281\n"
     ]
    }
   ],
   "source": [
    "#training file of uyiwebdata on English\n",
    "t0 = time.time()\n",
    "en = \"/home/work/ssCat/trains.en\"\n",
    "with open(en) as inputen:\n",
    "    tokens = []\n",
    "    boundaries = set()\n",
    "    boundaries_token = set()\n",
    "    offset = 0\n",
    "    for sent in inputen:\n",
    "        sent = nltk.word_tokenize(sent.decode(\"utf-8\"))\n",
    "        #print sent\n",
    "        if len(sent) >=1:\n",
    "            boundaries_token.add(sent[-1])\n",
    "            tokens.extend(sent)\n",
    "            offset += len(sent)\n",
    "            boundaries.add(offset-1)\n",
    "print len(tokens)     \n",
    "def punct_features(tokens, i):\n",
    "    return {'prev-2word': tokens[i-2],\\\n",
    "            'prev-word': tokens[i-1],\\\n",
    "            'prev-1letter-capi':tokens[i-1][0].isupper(),\\\n",
    "            'predigit': tokens[i-1].isdigit(),\\\n",
    "            'len-pre-word': len(tokens[i-1]),\\\n",
    "            'punct': tokens[i],\\\n",
    "            'punct-capitalised':tokens[i][0].isupper(),\\\n",
    "            'punctdigit': tokens[i].isdigit(),\\\n",
    "            'len-next-word':len(tokens[i+1][0]),\\\n",
    "            'next-word-capitalized': tokens[i+1][0].isupper(),\\\n",
    "            'next-word-digit':tokens[i+1].isdigit()}\n",
    "\n",
    "featuresets = [(punct_features(tokens, i), (i in boundaries))\\\n",
    "               for i in range(1, len(tokens)-1) if tokens[i] in boundaries_token]\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]\n",
    "size_dev = int(len(train_set)*0.2)\n",
    "train_set,dev_set = train_set[size_dev:], train_set[:size_dev]\n",
    "print \"processing data time: \",time.time()-t0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(classifier, test_set, accuracy=True, f_measure=True, precision=True, recall=True):\n",
    "        \n",
    "        print(\"Evaluating {} results...\".format(type(classifier).__name__))\n",
    "        metrics_results = {}\n",
    "        if accuracy == True:\n",
    "            accuracy_score = nltk.classify.accuracy(classifier, test_set)\n",
    "            metrics_results['Accuracy'] = accuracy_score\n",
    "\n",
    "        gold_results = defaultdict(set)\n",
    "        test_results = defaultdict(set)\n",
    "        labels = set()\n",
    "        for i, (feats, label) in enumerate(test_set):\n",
    "            labels.add(label)\n",
    "            gold_results[label].add(i)\n",
    "            observed = classifier.classify(feats)\n",
    "            test_results[observed].add(i)\n",
    "\n",
    "        for label in labels:\n",
    "            if precision == True:\n",
    "                precision_score = eval_precision(gold_results[label],\n",
    "                    test_results[label])\n",
    "                metrics_results['Precision [{}]'.format(label)] = precision_score\n",
    "            if recall == True:\n",
    "                recall_score = eval_recall(gold_results[label],\n",
    "                    test_results[label])\n",
    "                metrics_results['Recall [{}]'.format(label)] = recall_score\n",
    "            if f_measure == True:\n",
    "                f_measure_score = eval_f_measure(gold_results[label],\n",
    "                    test_results[label])\n",
    "                metrics_results['F-measure [{}]'.format(label)] = f_measure_score\n",
    "\n",
    "        # Print evaluation results (in alphabetical order)\n",
    "        for result in sorted(metrics_results):\n",
    "            print('{}: {}'.format(result, metrics_results[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  32.6861569881\n",
      "0.952293641459\n",
      "0.955475293458\n",
      "Evaluating SklearnClassifier results...\n",
      "Accuracy: 0.955475293458\n",
      "F-measure [False]: 0.975462438656\n",
      "F-measure [True]: 0.759905977166\n",
      "Precision [False]: 0.96673695667\n",
      "Precision [True]: 0.833517495396\n",
      "Recall [False]: 0.984346862446\n",
      "Recall [True]: 0.698241283554\n"
     ]
    }
   ],
   "source": [
    "#using libsvm\n",
    "t1 = time.time()\n",
    "classifier = SklearnClassifier(LinearSVC()).train(train_set)\n",
    "print \"training time: \",time.time()-t1 \n",
    "print nltk.classify.accuracy(classifier, dev_set)\n",
    "print nltk.classify.accuracy(classifier, test_set)\n",
    "evaluate(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training time:  4158.4049499\n",
      "0.119447145724\n",
      "0.127076350093\n",
      "Evaluating SklearnClassifier results...\n",
      "Accuracy: 0.127076350093\n",
      "F-measure [False]: None\n",
      "F-measure [True]: 0.225497323376\n",
      "Precision [False]: None\n",
      "Precision [True]: 0.127076350093\n",
      "Recall [False]: 0.0\n",
      "Recall [True]: 1.0\n"
     ]
    }
   ],
   "source": [
    "t3 = time.time()\n",
    "classifier = SklearnClassifier(OneClassSVM()).train(train_set)\n",
    "print \"training time: \",time.time()-t3\n",
    "print nltk.classify.accuracy(classifier, dev_set)\n",
    "print nltk.classify.accuracy(classifier, test_set)\n",
    "evaluate(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t4 = time.time()\n",
    "classifier = SklearnClassifier(SVC()).train(train_set)\n",
    "print \"training time: \",time.time()-t4 \n",
    "print nltk.classify.accuracy(classifier, dev_set)\n",
    "print nltk.classify.accuracy(classifier, test_set)\n",
    "evaluate(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  1.87185192108\n",
      "0.967328177585\n",
      "0.969388849178\n",
      "Most Informative Features\n",
      "                   punct = '?'              True : False  =    118.0 : 1.0\n",
      "                   punct = ','             False : True   =     87.6 : 1.0\n",
      "                   punct = 'f'             False : True   =     86.5 : 1.0\n",
      "                   punct = '.'              True : False  =     69.8 : 1.0\n",
      "                   punct = '}'              True : False  =     48.5 : 1.0\n",
      "                   punct = 'o'             False : True   =     46.7 : 1.0\n",
      "                   punct = '!'              True : False  =     45.2 : 1.0\n",
      "                   punct = 'u'             False : True   =     39.1 : 1.0\n",
      "                   punct = '\\xa6'           True : False  =     38.0 : 1.0\n",
      "                   punct = '-'             False : True   =     31.0 : 1.0\n",
      "None\n",
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.969388849178\n",
      "F-measure [False]: 0.983870815875\n",
      "F-measure [True]: 0.700262467192\n",
      "Precision [False]: 0.976013450402\n",
      "Precision [True]: 0.823456790123\n",
      "Recall [False]: 0.991855719032\n",
      "Recall [True]: 0.609132420091\n"
     ]
    }
   ],
   "source": [
    "#using naive bayes\n",
    "t2 = time.time()\n",
    "classifier = classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print \"training time: \",time.time()-t2\n",
    "print nltk.classify.accuracy(classifier, dev_set)\n",
    "print nltk.classify.accuracy(classifier, test_set)\n",
    "print classifier.show_most_informative_features()\n",
    "evaluate(classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_sentences(words):\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, word in enumerate(words):\n",
    "        if word in '.?!;' and i != len(words)-1 and classifier.classify(punct_features(words, i)) == True:             #\n",
    "            sents.append(words[start:i+1])\n",
    "            start = i+1\n",
    "    if start < len(words):\n",
    "        sents.append(words[start:])\n",
    "    return sents\n",
    "\n",
    "teststring = \"If you have your own collection of text files that you would\\\n",
    " like to access using the above methods, you can easily load them with\\\n",
    "  the help of NLTK's PlaintextCorpusReader. Check the location of your \\\n",
    "  files on your file system; in the following example, we have taken \\\n",
    "  this to be the directory /usr/share/dict. Whatever the location, \\\n",
    "  set this to be the value of corpus_root.\"\n",
    "\n",
    "wl = nltk.word_tokenize(teststring)\n",
    "ss = segment_sentences(wl)\n",
    "print len(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *select even number sentence with sed*\n",
    "\n",
    "`sed -n 2~2p rall.en > first`\n",
    "`sed -n 'n;p'`\n",
    "\n",
    "* *select odd number sentence with sed*\n",
    "\n",
    "`sed -n 1~2p first >second`\n",
    "`sed -n 'p;n'`\n",
    "\n",
    "* *select tandomly about 1% of the total corpus*\n",
    "\n",
    "`perl -ne 'print if (rand() < .01)' forth > fifth`\n",
    "\n",
    "* *select sentence with length shorten than 60 tokens*\n",
    "\n",
    "`awk 'length($0)<60' fifth >sixth`\n",
    "\n",
    "* *select sentence exceed 80*\n",
    "\n",
    "`grep '^.\\{80\\}' file`\n",
    "\n",
    "`perl -nle 'print if length$_>79' file`\n",
    "\n",
    "`sed -n '/.\\{80\\}/p' file`       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
