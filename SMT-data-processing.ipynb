{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMT data processing manual\n",
    "## have fun!\n",
    "Following scripts are used for transform data extract from web database,the procedure are listed sequencially.\n",
    "\n",
    "1.The first few parts play with all the possible way to access a directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /bin/python\n",
    "#-*- coding:utf-8 \n",
    "import os\n",
    "path = '/home/work/multifieldData/'\n",
    "#os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = next(os.walk(path))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print glob.glob(\"/home/work/langData/*/*.zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = [os.path.join(path,fn) for fn in next(os.walk(path))[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for p in paths:\n",
    "    filenames = [os.path.join(p,fn) for fn in next(os.walk(p))[2]]\n",
    "    #print filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outpath = '/home/work/clasData/'\n",
    "for i,j in zip(tags,paths):       \n",
    "    #get tag and concatenante file to same category\n",
    "    i = i.split('-',-1)\n",
    "    #print i\n",
    "    filenames = [os.path.join(j,fn) for fn in next(os.walk(j))[2]]\n",
    "    \n",
    "    for order in range(len(i)-1):\n",
    "        directory = outpath+i[order]+'/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory,0755)\n",
    "            print \"make directory....\"\n",
    "        for fname in filenames :\n",
    "            if fname.split('.')[1] == 'zh-hk' or l.split('.') == 'zh-tw':\n",
    "                pass\n",
    "            else :\n",
    "                print os.listdir(outpath),fname\n",
    "                with open(directory+i[order]+'.'+fname.split('.')[1],'w+') as outfile:\n",
    "                    with open(fname) as infile:\n",
    "                        for line in infile:\n",
    "                            outfile.write(line)\n",
    "                            print \"done\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /bin/python\n",
    "#-*- coding:utf-8 \n",
    "#transform data into language specific dir\n",
    "import os\n",
    "import time\n",
    "t0 = time.time()\n",
    "path = '/home/work/multifieldData/'\n",
    "outpath = '/home/work/SSData/'\n",
    "\n",
    "tags = next(os.walk(path))[1]\n",
    "paths = [os.path.join(path,fn) for fn in next(os.walk(path))[1]]\n",
    "\n",
    "def writefile(filename,langmark):\n",
    "    with open(directory+t[o]+'.'+langmark,'a+') as outfile:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "                #print \"done\"  \n",
    "\n",
    "for t,p in zip(tags,paths):\n",
    "     \n",
    "    #get tag and concatenante file to same category\n",
    "    t = t.rsplit('-',1)\n",
    "    filenames = [os.path.join(p,fn) for fn in next(os.walk(p))[2]]\n",
    "    \n",
    "    for o in range(len(t)-1):\n",
    "        lang1 = filenames[0]\n",
    "        lang2 = filenames[1]\n",
    "        lang1mark = lang1.split('.')[1]\n",
    "        lang2mark = lang2.split('.')[1]\n",
    "        langm = lang1mark+'_'+lang2mark\n",
    "        directory = outpath+langm+'/'+t[o]+'/'\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory,0755)\n",
    "            print \"make directory....\"\n",
    "        writefile(lang1,lang1mark)\n",
    "        writefile(lang2,lang2mark)\n",
    "print \"finished\",time.time()-t0\n",
    "               \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#concatenante same language pairs despite the field\n",
    "import os\n",
    "path1 = '/home/work/SSData/zh-cn_en'\n",
    "path2 = '/home/work/SSData/en_zh-cn'\n",
    "lang1 = 'en'\n",
    "lang2 = 'cn'\n",
    "key = 'all.'\n",
    "directory = '/home/work/'+lang1+lang2+'/' \n",
    "\n",
    "def get_name(path):\n",
    "    allfile = []\n",
    "    for p in path:\n",
    "        allfile.extend([os.path.join(p,fn) for fn in next(os.walk(p))[2]])\n",
    "    return allfile\n",
    "def get_dir(path):\n",
    "    dirs = [os.path.join(path,fn) for fn in next(os.walk(path))[1]]\n",
    "    return dirs\n",
    "\n",
    "fs1 = get_name(get_dir(path1))\n",
    "fs2 = get_name(get_dir(path2))\n",
    "fs1.extend(fs2)\n",
    "\n",
    "#print len(fs1)\n",
    "def writefile(filename,lang):\n",
    "    with open(directory+key+lang,'a+') as outfile:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "                #print \"done\"\n",
    "        \n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory,0755)\n",
    "for s in fs1:\n",
    "    lang = s.split('.')[1]\n",
    "    writefile(s,lang)\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#detect language\n",
    "from langdetect import detect,detect_langs\n",
    "\n",
    "file1 = '/home/work/cnen/all.en'\n",
    "file2 = '/home/work/cnen/all.zh-cn'\n",
    "lang1 = \"en\"\n",
    "lang2 = \"zh-cn\"\n",
    "zh = open('/home/work/cnen/filter.cn','w+')\n",
    "en = open('/home/work/cnen/filter.en','w+')\n",
    "excepten = open('/home/work/cnen/filter.excepten','w+')\n",
    "exceptzh = open('/home/work/cnen/filter.exceptzh','w+')\n",
    "\n",
    "with open(file1) as input1:\n",
    "    with open(file2) as input2:\n",
    "        for line1,line2 in zip(input1,input2):\n",
    "            try:\n",
    "                l1 = detect(line1.decode('utf-8'))\n",
    "                l2 = detect(line2.decode('utf-8'))\n",
    "                if l1 == lang1 and l2 == lang2:\n",
    "                    en.write(line1)\n",
    "                    zh.write(line2)\n",
    "                elif l1 == lang2 and l2 == lang1:\n",
    "                    en.write(line2)\n",
    "                    zh.write(line1)\n",
    "                elif l1 == lang1 and l2 != lang2:\n",
    "                    en.write(line1)\n",
    "                    zh.write(line2)\n",
    "                elif l1 != lang1 and l2 == lang2:\n",
    "                    en.write(line1)\n",
    "                    zh.write(line2)\n",
    "                elif l1 != lang1 and l2 != lang2:\n",
    "                    excepten.write(line1)\n",
    "                    exceptzh.write(line2)\n",
    "                else:\n",
    "                    excepten.write(line1)\n",
    "                    exceptzh.write(line2)\n",
    "            except:\n",
    "                excepten.write(line1)\n",
    "                exceptzh.write(line2)                       \n",
    "zh.close()\n",
    "en.close()\n",
    "excepten.close()\n",
    "exceptzh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split data into training tuning and testing data\n",
    "import random\n",
    "file1 = '/home/work/cnen/vehicle/data/vehicle.en'\n",
    "file2 = '/home/work/cnen/vehicle/data/vehicle.zh-cn'\n",
    "data = []\n",
    "\n",
    "with open(file1) as input1:\n",
    "    with open(file2) as input2:\n",
    "        for line1,line2 in zip(input1,input2):\n",
    "            data.append((line1,line2))\n",
    "random.shuffle(data)\n",
    "trainsize = int(len(data) * 0.2)\n",
    "train, rest = data[trainsize:], data[:trainsize]\n",
    "devsize = int(len(rest) * 0.2)\n",
    "dev,test = rest[devsize:], rest[:devsize]\n",
    "\n",
    "def write_file(dat,filename1,filename2):\n",
    "    with open(filename1,'w') as output1:\n",
    "        with open(filename2,'w') as output2:\n",
    "            for d in dat:\n",
    "                output1.write(d[0])\n",
    "                output2.write(d[1])\n",
    "#name file                \n",
    "directory = file1.rsplit('/',1)[0]+'/'\n",
    "name1 = file1.rsplit('/',1)[1]\n",
    "name2 = file2.rsplit('/',1)[1]\n",
    "trainen = directory+'train'+name1\n",
    "trainzh = directory+'train'+name2\n",
    "deven = directory+'dev'+name1\n",
    "devzh = directory+'dev'+name2\n",
    "testen = directory+'test'+name1\n",
    "testzh = directory+'test'+name2\n",
    "\n",
    "write_file(train,trainen,trainzh)\n",
    "write_file(dev,deven,devzh)\n",
    "write_file(test,testen,testzh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinRange  timemust be less than  <:fc 2>.MaxRange <:/fc>.\n",
      "Database Mirroring Monitor could not save the changes for warning  at server instance .\n",
      "Update Membership - \n",
      "No status request was found for the synchronization request (ID=). This may indicate that the server is too busy to process requests.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "problemf = '/home/work/multifieldData/IT-6361'\n",
    "sl = ['{\\cs6\\f1\\cf6\\lang1024 }MinRange {\\cs6\\f1\\cf6\\lang1024 time}must be less than {\\cs6\\f1\\cf6\\lang1024 <:fc 2>}.MaxRange{\\cs6\\f1\\cf6\\lang1024 <:/fc>}.',\\\n",
    "\"Database Mirroring Monitor could not save the changes for warning '{0}' at server instance '{1}'.\",\\\n",
    "'Update Membership - {0}','No status request was found for the synchronization request (ID={0}). This may indicate that the server is too busy to process requests.']\n",
    "\n",
    "for line in sl:\n",
    "    #line = re.sub(r'\\{((\\\\.*)+ .*)}?','',line)\n",
    "    #line = \n",
    "    line = re.sub(r'\\{\\\\.*? \\}','',line)\n",
    "    line = re.sub(r'\\{\\\\.*?( .+?)\\}',lambda m:m.group(1),line)\n",
    "    line = re.sub(r\"'{[0-9]}'\",\"\",line)\n",
    "    line = re.sub(r\"{[0-9]}\",\"\",line)\n",
    "    print line\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import re\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import codecs\n",
    "\n",
    "problemf = '/home/work/multifieldData/IT-6361/targetTxt.zh-cn'\n",
    "\n",
    "with open(problemf) as inputfile:\n",
    "    with codecs.open(\"/home/work/multifieldData/IT-6361/test.cn\",'w') as output:\n",
    "        for line in inputfile:\n",
    "            line = re.sub(r'\\{\\\\.*?( .+?)\\}',lambda m:m.group(1),line)\n",
    "            line = re.sub(r'\\{\\\\.*? \\}','',line)\n",
    "            line = re.sub(r'<.*?>','',line)\n",
    "            line = re.sub(r\"'{[0-9]}'\",\"\",line)\n",
    "            line = re.sub(r\"{[0-9]}\",\"\",line)\n",
    "            line = re.sub(r'\\{\\\\.*?( .+?)\\}',lambda m:m.group(1),line)\n",
    "            #line = re.sub(r'&quot;','\"',line)\n",
    "            #line = re.sub(r'&amp;','&',line)\n",
    "            #line = re.sub(r'&lt;','<',line)\n",
    "            #line = re.sub(r'&gt;','>',line)\n",
    "            #line = re.sub(r'&apos;','',line)\n",
    "            line = re.sub(r'\\\\r\\\\n','',line)\n",
    "            line = re.sub(r'\\\\n','',line)\n",
    "            line = re.sub(r'{\\d\\]\\[\\d}','',line)\n",
    "            output.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
